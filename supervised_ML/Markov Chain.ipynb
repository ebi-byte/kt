{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov Property"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Markov property refers to the memoryless property of a stochastic process.\n",
    "\n",
    "**A stochastic process has the Markov property if the conditional probability distribution of future states of the process depends only upon the present state, not on the sequence of events that preceded it.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In probability theory and related fields, a Markov process is a stochastic process that satisfies the Markov property (sometimes characterized as \"memorylessness\"). Roughly speaking, a process satisfies the Markov property if one can make predictions for the future of the process based solely on its present state just as well as one could knowing the process's full history, hence independently from such history, that is, conditional on the present state of the system, its future and past states are independent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a Markov Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Markov chain is a type of Markov process that has either a discrete state space or a discrete index set (often representing time), but the precise definition of a Markov chain varies. For example, it is common to define a Markov chain as a Markov process in either discrete or continuous time with a countable state space (thus regardless of the nature of time), but it is also common to define a Markov chain as having discrete time in either countable or continuous state space (thus regardless of the state space)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A state space is the set of all possible configurations of a system. For example, a system in queueing theory defining the number of customers in a line would have state space {0, 1, 2, 3, ...}. The changes of state of the system are called transitions. The probabilities associated with various state changes are called transition probabilities. The process is characterized by a state space, a transition matrix describing the probabilities of particular transitions, and an initial state (or initial distribution) across the state space. By convention, we assume all possible states and transitions have been included in the definition of the process, so there is always a next state, and the process does not terminate. \n",
    "A discrete-time random process involves a system which is in a certain state at each step, with the state changing randomly between steps. The steps are often thought of as moments in time, but they can equally well refer to physical distance or any other discrete measurement. Formally, the steps are the integers or natural numbers, and the random process is a mapping of these to states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/2/2b/Markovkate_01.svg\" style=\"height: 300px;\" />  \n",
    "A diagram representing a two-state Markov process, with the states labelled E and A. Each number represents the probability of the Markov process changing from one state to another state, with the direction indicated by the arrow. For example, if the Markov process is in state A, then the probability it changes to state E is 0.4, while the probability it remains in state A is 0.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples\n",
    "##### Drunkard's Walk\n",
    "A famous Markov chain is the so-called \"drunkard's walk\", a random walk on the number line where, at each step, the position may change by +1 or −1 with equal probability. From any position there are two possible transitions, to the next or previous integer. The transition probabilities depend only on the current position, not on the manner in which the position was reached. For example, the transition probabilities from 5 to 4 and 5 to 6 are both 0.5, and all other transition probabilities from 5 are 0. These probabilities are independent of whether the system was previously in 4 or 6.\n",
    "\n",
    "##### Dietary Habit\n",
    "Another example is the dietary habits of a creature who eats only grapes, cheese, or lettuce, and whose dietary habits conform to the following rules:   \n",
    "It eats exactly once a day.  \n",
    "If it ate cheese today, tomorrow it will eat lettuce or grapes with equal probability.  \n",
    "If it ate grapes today, tomorrow it will eat grapes with probability 1/10, cheese with probability 4/10, and lettuce with probability 5/10.   \n",
    "If it ate lettuce today, tomorrow it will eat grapes with probability 4/10 or cheese with probability 6/10. It will not eat lettuce again tomorrow.  \n",
    "\n",
    "This creature's eating habits can be modeled with a Markov chain since its choice tomorrow depends solely on what it ate today, not what it ate yesterday or any other time in the past. One statistical property that could be calculated is the expected percentage, over a long period, of the days on which the creature will eat grapes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gambling Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that you start with 10 dollars, and you wager 1 dollar on an unending, fair, coin toss indefinitely, or until you lose all of your money. If <math>X_n</math> represents the number of dollars you have after ''n'' tosses, with <math>X_0 = 10</math>, then the sequence {X_n : n *E* N} is a Markov process. If I know that you have 12 dollars now, then it would be expected that with even odds, you will either have 11 or 13 dollars after the next toss. This guess is not improved by the added knowledge that you started with 10 dollars, then went up to 11, down to 10, up to 11, and then to 12 dollars.\n",
    "\n",
    "The process described here is a Markov chain on a countable state space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Birth Death Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If one pops one hundred kernels of popcorn in an oven, each kernel popping at an independent exponentially-distributed time, then this would be a continuous-time Markov process. If X_t denotes the number of kernels which have popped up to time t, the problem can be defined as finding the number of kernels that will pop in some later time. The only thing one needs to know is the number of kernels that have popped prior to the time \"t\". It is not necessary to know when they popped, so knowing \n",
    "X_t for previous times \"t\" is not relevant.\n",
    "\n",
    "The process described here is an approximation of a Poisson point process – Poisson processes are also Markov processes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete Time Markov Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A discrete-time Markov chain is a sequence of random variables ''X''<sub>1</sub>, ''X''<sub>2</sub>, ''X''<sub>3</sub>, ... with the Markov property, namely that the probability of moving to the next state depends only on the present state and not on the previous states:\n",
    "\n",
    "***P(Xn+1 = x | X1 = x1, X2 = x2, ..., Xn = xn) = P(Xn+1 = x | Xn = xn)***\n",
    "\n",
    "The possible values of ''X''<sub>''i''</sub> form a countable set ''S'' called the state space of the chain.\n",
    "\n",
    "Markov chains are often described by a sequence of directed graphs, where the edges of graph ''n'' are labeled by the probabilities of going from one state at time ''n'' to the other states at time ''n''&nbsp;+&nbsp;1, P(X_n+1 =x |X_n=x_n). The same information is represented by the transition matrix from time ''n'' to time ''n''&nbsp;+&nbsp;1. However, Markov chains are frequently assumed to be time-homogeneous (see variations below), in which case the graph and matrix are independent of ''n'' and are thus not presented as sequences.\n",
    "\n",
    "These descriptions highlight the structure of the Markov chain that is independent of the initial distribution Pr(X_1=x_1). When time-homogeneous, the chain can be interpreted as a state machine assigning a probability of hopping from each vertex or state to an adjacent one. The probability Pr(X_n=x | X_1=x_1) of the machine's state can be analyzed as the statistical behavior of the machine with an element <math>x_1</math> of the state space as input, or as the behavior of the machine with the initial distribution P(X_1 = y)=(x_1 =y) of states as input.\n",
    "\n",
    "The fact that some sequences of states might have zero probability of occurring corresponds to a graph with multiple connected components, where we omit edges that would carry a zero transition probability. For example, if ''a'' has a nonzero probability of going to ''b'', but ''a'' and ''x'' lie in different connected components of the graph, then P(X_n+1 = b | X_n = a) is defined, while Pr(X_n+1 = b | X_1 = x, ... , X_n = a) is not.\n",
    "\n",
    "#### Variations\n",
    "1. Time-homogeneous Markov chains (or stationary Markov chains) are processes where  \n",
    "Pr(X_n+1 = x ∣ X_n = y) = Pr(X_n = x ∣ X_n−1 = y)  \n",
    "\n",
    "for all n. The probability of the transition is independent of n.\n",
    "2. A Markov chain with memory (or a Markov chain of order m)\n",
    "where m is finite, is a process satisfying  \n",
    "Pr(X_n = x_n ∣ X_n−1 = x_n−1, X_n−2 = x_n−2, … , X_1 = x_1) = Pr(X_n = x_n ∣ X_n−1 = x_n−1, X_n−2 = x_n−2, … , X_n−m = x_n−m)  for  n > m    \n",
    "\n",
    "In other words, the future state depends on the past m states. It is possible to construct a chain (Y_n) from (X_n) which has the 'classical' Markov property by taking as state space the ordered m-tuples of X values, ie. Y_n = (X_n , X_n−1, … , X_n−m + 1) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transition Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A transition matrix Pt for Markov chain {X} at time t is a matrix containing information on the probability of transitioning between states. In particular, given an ordering of a matrix's rows and columns by the state space S, the (i, j)th element of the matrix is given by\n",
    "\n",
    "$$Pt(ij) = P(Xt+1 = j | Xt = i)$$\n",
    "\n",
    "This means each row of the matrix is a probability vector, and the sum of its entries is 1.\n",
    "\n",
    "Transition matrices have the property that the product of subsequent ones describes a transition along the time interval spanned by the transition matrices. That is to say, Po.P1 has in its (ij)th position the probability that X2 = j given that X0 = i. And in general, the (ij)th poistion of Pt.P(t+1)...P(t+k) is the probability P(X(t+k+1) = j | Xt = i)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building A Markov Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://upload.wikimedia.org/wikipedia/commons/9/95/Finance_Markov_chain_example_state_space.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A state diagram for a simple example is shown in the figure on the right, using a directed graph to picture the state transitions. The states represent whether a hypothetical stock market is exhibiting a bull market, bear market, or stagnant market trend during a given week. According to the figure, a bull week is followed by another bull week 90% of the time, a bear week 7.5% of the time, and a stagnant week the other 2.5% of the time. Labelling the state space {1 = bull, 2 = bear, 3 = stagnant} the transition matrix for this example is \n",
    "\n",
    "<math>P = \\begin{bmatrix}\n",
    "0.9 & 0.075 & 0.025 \\\\\n",
    "0.15 & 0.8 & 0.05 \\\\\n",
    "0.25 & 0.25 & 0.5\n",
    "\\end{bmatrix}.</math>\n",
    "\n",
    "The distribution over states can be written as a stochastic row vector X with the relation Xn+1 = Xn.P. So if at time n, the system is in state Xn, then three time periods later, at time n+3, the distribution is:\n",
    "\n",
    "<math>\\begin{align}\n",
    "X^{(n+3)} &= X^{(n+2)} P = \\left( X^{(n+1)} P \\right) P \\\\\n",
    "&= X^{(n+1)} P^2= \\left( X^{(n)} P \\right) P^2\\\\\n",
    "&= X^{(n)} P^3 \\\\\n",
    "\\end{align}</math>\n",
    "\n",
    "In particular, if at time n the system is in state 2 (bear), then at time n + 3 the distribution is\n",
    "\n",
    "<math>\\begin{align}\n",
    "x^{(n+3)} &= \\begin{bmatrix} 0 & 1 & 0 \\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "0.9 & 0.075 & 0.025 \\\\\n",
    "0.15 & 0.8 & 0.05 \\\\\n",
    "0.25 & 0.25 & 0.5\n",
    "\\end{bmatrix}^3 \\\\[5pt]\n",
    "&= \\begin{bmatrix} 0 & 1 & 0 \\end{bmatrix} \\begin{bmatrix}\n",
    "0.7745 & 0.17875 & 0.04675 \\\\\n",
    "0.3575 & 0.56825 & 0.07425 \\\\\n",
    "0.4675 & 0.37125 & 0.16125 \\\\\n",
    "\\end{bmatrix} \\\\[5pt]\n",
    "& = \\begin{bmatrix} 0.3575 & 0.56825 & 0.07425 \\end{bmatrix}.\n",
    "\\end{align}</math>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the transition matrix it is possible to calculate, for example, the long-term fraction of weeks during which the market is stagnant, or the average number of weeks it will take to go from a stagnant to a bull market. Using the transition probabilities, the steady-state probabilities indicate that 62.5% of weeks will be in a bull market, 31.25% of weeks will be in a bear market and 6.25% of weeks will be stagnant, since:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<math> lim N-inf PN=\n",
    "\\begin{bmatrix}\n",
    "0.625 & 0.3125 & 0.0625 \\\\\n",
    "0.625 & 0.3125 & 0.0625 \\\\\n",
    "0.625 & 0.3125 & 0.0625\n",
    "\\end{bmatrix}</math>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability of States with progressing steps\n",
    "\n",
    "Consider a set of families. Every family falls into one of the following six states. \n",
    "\n",
    "The states are \\(S_1 = \\{AA, AA\\}\\), \\(S_2 = \\{AA, Aa\\}\\), \\(S_3 = \\{AA, aa\\}\\), \\(S_4=\\{Aa,Aa\\}\\), \\(S_5 = \\{Aa, aa\\}\\) and \\(S_6 = \\{aa, aa\\}\\).\n",
    "\n",
    "The idea is that each pair of parents give birth to two children.For example, the parents \\(S_2 = \\{AA, Aa\\}\\) can give birth to {{AA, AA}, {AA, Aa}, {Aa, Aa}}. Such kind of rules results in the following state transition matrix.\n",
    "\n",
    "$$\\begin{pmatrix}1 & 0 & 0 & 0 & 0 & 0 \\\\ 1/4 & 1/2 & 0 & 1/4 & 0 & 0\\\\ 0 & 0 & 0 & 1 & 0 & 0\\\\ 1/16 & 1/4 & 1/8 & 1/4 & 1/4 & 1/16\\\\ 0 & 0 & 0 & 1/4 & 1/2 & 1/4\\\\ 0 & 0 & 0 & 0 & 0 & 1\\end{pmatrix}$$\n",
    "\n",
    "The rows mean from which state you start, the colums are the states you can get to.\n",
    "\n",
    "We will plot all the possible transitions ranging from step size 1 to 20 as the probabilities of reaching a state if we start from state S3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3de5xVdb3/8ddnZoCRg4ox9EMbFeIWJlfnoGIkZREqaaU5KJWXxAzRrFOP4zmeHxd/P09mnTRDIeBnmKZwio4RkpJHJRRvwz25xOCxGMUcvKCE3GY+vz/22uOeYe+ZNbP2mr1n9vv5eKzH3mvt9V3ruxfD+uzvZX2/5u6IiEjhKsp1BkREJLcUCERECpwCgYhIgVMgEBEpcAoEIiIFriTXGWitsrIy79u3b66zISLSoaxZs2a3u/dO91mHCwR9+/alqqoq19kQEelQzOwvmT5T1ZCISIFTIBARKXAKBCIiBa7DtRGIiMTp0KFD1NTUsH///lxnpU1KS0spLy+nS5cuodMoEIiIpKipqeHoo4+mb9++mFmus9Mq7s6bb75JTU0N/fr1C50utkBgZvcCE4E33P3UNJ8b8BPgPGAfcIW7r40jL1WvV7Fk+5KG9YsGXkRFn4pQaf/8ibHU7d59xPbisjIGPb0qa3kUkfywf//+DhkEAMyMXr16UVtb26p0cZYIFgKzgV9k+PxcYGCwnA7MCV6zat+hfdz45I3sObinYdvTrz7NiotXcFTJUS2mTxcEmtsuIh1fRwwCSW3Je2yNxe7+R+CtZna5EPiFJzwH9DSz47Odj/mb5nOg7kCjbfsP72f+xvnZPpWISIeUy15DHwF2pqzXBNuOYGbXmFmVmVW1tsizeNti9tc1bvTZX7efRdsWtTK7IiLt59Zbb+XjH/84w4YNY8SIETz//PPMnj2bAQMGYGbszmKtRC4DQbryS9pZctx9nrtXuHtF795pn5DOqHJwJaXFpY22lRaXMmnwpFYdR0Skqbkrd7B6R+Mb8uodu5m7ckek4z777LMsW7aMtWvXsnHjRh5//HFOPPFEzjrrLB5//HFOPvnkSMdvKpeBoAY4MWW9HHgt2yeZMnQK3Yq7NdpWWlLKlGFTsn0qESkww8qPZdqD6xqCweodu5n24DqGlR8b6bi7du2irKyMbt0S966ysjJOOOEERo4cSRxjreUyECwFvmYJZwB73H1Xtk/SvUt37vzUnUz86MSG5Y5xd4RqKIZE76DWbBeRwjGmfxmzLxvJtAfX8eMV25j24DpmXzaSMf2j3R/Gjx/Pzp07GTRoEFOnTmXlypVZynF6cXYffQgYB5SZWQ0wA+gC4O5zgeUkuo5Wk+g+emVceanoUxG6u2hT6iIqIs0Z07+Mr5x+Enc9Uc0Nnx4QOQgA9OjRgzVr1rBq1SqefPJJKisrue2227jiiiuiZziN2AKBu1/awucOXBfX+UVE2sPqHbt54Pm/csOnB/DA83/ljP69shIMiouLGTduHOPGjWPo0KHcd999sQUCjTUkItJGyTaB2ZeN5DvjBzdUEzVtQG6tbdu2sX379ob19evXZ72BOJUCgYhIG22s2dOoTSDZZrCxZk8LKZu3d+9eLr/8ck455RSGDRvG5s2bmTlzJnfddRfl5eXU1NQwbNgwrr766mx8DSxRQ9NxVFRUuCamEZG4bNmyhSFDhuQ6G5Gk+w5mtsbd0zaWqkQgIlLgFAhERAqcAoGISIFTIBARKXAKBCIiBU6BQESkwCkQiIjkoXTDUE+ePJnBgwdz6qmnctVVV3Ho0KGsnEuBQEQkioN/h8dnwW0nwX/fAgf3RT5kpmGoJ0+ezNatW9m0aRPvv/8+CxYsyMIX0OT1IiJt98ozsPgrcOh9OPw+PHsPVP0cKh+Avme1+bDphqEGOOGEExr2GT16NDU1NdHyH1CJQESkrdbeB++/lQgCkHh9/63E9ghaGob60KFD3H///UyYMCHSeZIUCERE8kxyGOp58+bRu3dvKisrWbhwYcPnU6dO5ZOf/CRjx47NyvlUNSQikocyDUM9a9Ysamtr+dnPfpa1c6lEICLSVqMuh6M+BMkZD0uOSqyPujzSYTMNQ71gwQIee+wxHnroIYqKsnf7VolARKSt+p4F334JVv0IXlwA/zgFxv4TdO0e6bB79+7l+uuv55133qGkpIQBAwYwb948+vTpw8knn8yZZ54JwJe+9CWmT58e+WsoEIiIRNG1O5wzPbFkyWmnncbq1auP2H748OGsnSOVqoZERAqcAoGISIFTIBARKXAKBCIiBU6BQESkwCkQiIgUOAUCEZE8lG4Y6q9//esMHz6cYcOGcfHFF7N3796snEvPEYiIRFD1ehVLti9pWL9o4EVU9KmIdMzUYai7devG7t27OXjwIHfccQfHHHMMAN/5zneYPXs2N910U6RzgQKBiEib7Tu0jxufvJE9B/c0bHv61adZcfEKjkoOO9EGmYahTnJ33n//fcyszedIpaohEZE2mr9pPgfqDjTatv/wfuZvnB/puM0NQ33llVfSp08ftm7dyvXXXx/pPEkKBCIibbR422L21+1vtG1/3X4WbVsU6bjNDUP985//nNdee40hQ4awePHiSOdJUiAQEWmjysGVlBaXNtpWWlzKpMGTIh87OQz1rFmzmD17NkuWLGn0WWVlZaNtUSgQiIi00ZShU+hW3K3RttKSUqYMmxLpuOmGoT7ppJOorq4GEm0Ev/vd7/jYxz4W6TxJsTYWm9kE4CdAMbDA3W9r8vlJwH1Az2Cfm9x9eZx5EhHJlu5dunPnp+48otdQlIZiSD8M9dy5c/niF7/Iu+++i7szfPhw5syZE/UrADEGAjMrBu4GPgvUAC+a2VJ335yy278B/+nuc8zsFGA50DeuPImIZFtFn4rI3UWbyjQM9TPPPJPV8yTFWTU0Gqh295fd/SCwCLiwyT4OHBO8PxZ4Lcb8iIhIGnEGgo8AO1PWa4JtqWYCXzGzGhKlgbR9oczsGjOrMrOq2traOPIqIlKw4gwE6Z508CbrlwIL3b0cOA+438yOyJO7z3P3Cnev6N27dwxZFREpXHEGghrgxJT1co6s+vk68J8A7v4sUAqUISIi7SbOQPAiMNDM+plZV2ASsLTJPn8FzgEwsyEkAoHqfkRE2lFsgcDdDwPTgMeALSR6B71kZreY2QXBbv8ETDGzDcBDwBXu3rT6SEREYhTrA2XuvtzdB7l7f3e/Ndg23d2XBu83u/tZ7j7c3Ue4+4o48yMi0lGkG4Y66frrr6dHjx5ZO5dGHxURaaM/f2Isdbt3H7G9uKyMQU+vavNxMw1DDVBVVcU777zT5mOnoyEmRETaKF0QaG57WOmGoT7hhBOoq6vje9/7Hrfffnuk4zelQCAikmcyDUM9e/ZsLrjgAo4//visnk9VQyIieSY5DPWqVat48sknqays5IYbbmD58uU89dRTWT+fAoGISB5KDkM9btw4hg4dyqWXXkqvXr0YMGAAAPv27WPAgAENI5JGoaohEZE8k24Y6m984xu8/vrrvPLKK7zyyit07949K0EAVCIQEWmz4rKyjL2Gokg3DPW8efMiHbM5CgQiIm0UpYtoczINQ51q7969WTufqoZERAqcAoGISIFTIBARKXAKBCIiBU6BQESkwCkQiIgUOAUCEZE8lG4Y6iuuuIJ+/foxYsQIRowYwfr167NyLj1HICISQc22t1k2ewN1h+op7lLExGnDKR98XKRjNjcM9Q9/+EMuvvjibGS9gUoEIiJtVLPtbR65OxEEAOoO1fPI3Ruo2fZ2pONmGoY6LgoEIiJttGz2Bg4frG+07fDBepbN3hDpuJmGoQa4+eabGTZsGN/+9rc5cOBApPMkKRCIiLRRsiQQdntYyWGo582bR+/evamsrGThwoV8//vfZ+vWrbz44ou89dZb/OAHP4h0niQFAhGRNirukv4Wmml7q44dDEM9a9YsZs+ezZIlSzj++OMxM7p168aVV17JCy+8EPk8oEAgItJmE6cNp6Rr49toSddEg3EU6YahPvnkk9m1axcA7s7DDz/MqaeeGuk8Seo1JCLSRuWDj+P864Y36jV0/nXRew1lGob6kksuoba2FndnxIgRzJ07NyvfQ4FARCSC8sHHce1Px2X1mJmGoX7iiSeyep4kVQ2JiBQ4BQIRkQKnQCAiUuAUCERECpwCgYhIgVMgEBEpcKECgZktMbPzzUyBQ0SkHaQbhtrdufnmmxk0aBBDhgzhrrvuysq5wj5HMAe4ErjLzH4FLHT3rS0lMrMJwE+AYmCBu9+WZp9LgJmAAxvc/bKQeRIRyR8zZyaWLMg0DPXChQvZuXMnW7dupaioiDfeeCMr5wv1C9/dH3f3ycAo4BXgD2a22syuNLMu6dKYWTFwN3AucApwqZmd0mSfgcC/AGe5+8eBG9v8TUREcmnWrKwdKtMw1HPmzGH69OkUFSVu3R/+8Iezcr7QVT1m1gu4ArgaWEfil/4o4A8ZkowGqt39ZXc/CCwCLmyyzxTgbnd/G8DdsxPeREQ6sEzDUO/YsYPFixdTUVHBueee22g8oijCthH8BlgFdAc+7+4XuPtid78e6JEh2UeAnSnrNcG2VIOAQWb2jJk9F1QlpTv/NWZWZWZVtbW1YbIsIhK/mTPBLLHAB+8jVhFlGob6wIEDlJaWUlVVxZQpU7jqqqsifwUAc/eWdzI7z92XN9nWzd0zzopgZl8GPufuVwfrXwVGB8Ejuc8y4BBwCVBOItic6u7vZDpuRUWFV1VVtZhnEZG22LJlC0OGDGl9QjMIcT9ti1//+tfcd999bN++nUcffZS+ffvi7vTs2ZM9e/YcsX+672Bma9y9It3xw1YN/d80255tIU0NcGLKejnwWpp9fuvuh9z9f4BtwMCQeRIR6ZQyDUP9hS98oWHguZUrVzJo0KCsnK/ZXkNm1odEdc5RZjYSCMo/HEOimqg5LwIDzawf8CowCWjaI+hh4FJgoZmVkagqerlV30BEJB/MmJG1Q2UahrqkpITJkydzxx130KNHDxYsWJCV87XUffRzJBqIy4Efp2x/D/jX5hK6+2EzmwY8RqL76L3u/pKZ3QJUufvS4LPxZrYZqAO+5+5vtumbiIjkUpa6jkLmYagBHnnkkaydJ6nZQODu9wH3mdlF7r6ktQcP2hWWN9k2PeW9A98JFhERyYGWqoa+4u4PAH3N7Iibtbv/OE0yERHpQFqqGvqH4DVTF1ERkU7H3bFkl9AOJkxP0KZaqhr6WfCavUfmRETyWGlpKW+++Sa9evXqcMHA3XnzzTcpLS1tVbqWqoaaHdHI3W9o1dlERPJceXk5NTU1dNSHV0tLSykvL29Vmpaqhta0PTsiIh1Ply5d6NevX66z0a7C9BoSEZFOrKWqoTvd/UYz+x2JYaIbcfcLYsuZiIi0i5aqhu4PXn8Ud0ZERCQ3WqoaWhO8rjSzrsDHSJQMtgVDS4uISAcXaoYyMzsfmAvsIDHeUD8z+4a7/z7OzImISPzCTlX5H8Cn3L0awMz6A48ACgQiIh1c2GGo30gGgcDLgGYTExHpBFrqNfSl4O1LZrYc+E8SbQRfJjHMtIiIdHAtlQg+HyylwN+As4FxQC1wXKw5ExER5q7cweoduxMrwVDXq3fsZu7KHVk7R7OBwN2vbGbJzmSZIiKdWNQb+bDyY5n24LrEMWbNYvWO3Ux7cB3Dyo/NWh7DTl5fambXmdk9ZnZvcslaLkRE8lSub+Rj+pcx+7KRTHtwHQDTHlzH7MtGMqZ/Wau/SyZhG4vvB/qQmLFsJYkZy97LWi5ERGLS4W/kM2cyZkBv1k4fD8Da6eMZM6B3VmdEw91bXIB1wevG4LUL8ESYtNleTjvtNBeRwjHnqWp/pro2sTJjhru7P1Nd63Oeqg6V/pnqWh95y4rEMaDxekjJNA6tTuszZrjDkUvwXWI/f4DEFMHp7/GZPmi0E7wQvP4ROBUoA14OkzbbiwKBSMeiG3m082fj+7tnJxBcTaKX0Nl88AzBN8KkzfaiQCDSsehGHu37Rw2kSZEDQT4tCgQi7SsbNyLdyKPfyKPKRomgF/BTYC2JyWruBHqFSZvtRYFApH1F/kWvG3leyEYg+APwv4F+wfJvwONh0mZ7USAQaZ2c/6KPmF438uzIRiBYk2ZbxoPGuSgQiLROrn/R60aeH7IRCH4ETCLx3EERcAkwK0zabC8KBFJoOvovet3I80ObAwGJh8beDV7rgcPBUg+821zauBYFAik0Hf0XveSH5gJBS2MNHe3uxwSvRe5eEixF7n5M2IfWRKTtsvFk6urqWkbdsgKAUbesYHV1begnUzfW7PngfDNmNORnY82etnwdyUeZIkTTBbiARBXRj4CJYdNle1GJQDqSrFSL6Be9ZAFtLREkmdltwLeAzcHyrWCbiDQjKyNH6he9xMwSgaKFncw2AiPcvT5YLyYx/tCwmPN3hIqKCq+qqmrv04q0WfLmv3b6eEbdsqLVI0cm08++bCRjBvRmdXVtLCNQSudmZmvcvSLdZ2FHHwXomfI+ewNhi3RmWRg5Ur/oJW5hA8H3gXVmttDM7iPxdPG/t5TIzCaY2TYzqzazm5rZ72IzczNLG61EciXy7FARq3UArj27/we//IN0Y/qXce3Z/UMfQ6Q5LQYCMzPgaeAM4DfBcqa7L2ohXTFwN3AucApwqZmdkma/o4EbgOdbnXuRmEWt40+t1gEaev80BBeRPNBiIAhamx92913uvtTdf+vur4c49mig2t1fdveDwCLgwjT7/R/gdmB/azIu0h6idt1UtY50BGGrhp4zs39s5bE/AuxMWa8JtjUws5HAie6+rLkDmdk1ZlZlZlW1tbWtzIZIBBHr+FWtIx1B2EDwKRLBYIeZbTSzTUFPouZYmm0NXZTMrAi4A/inlk7u7vPcvcLdK3r37h0yyyJZkIU6fpF8FzYQnAt8FPg08HlgYvDanBrgxJT1cuC1lPWjScx29pSZvUKiDWKpGowlm6I29qqOXwpBs4HAzErN7Ebge8AE4FV3/0tyaeHYLwIDzayfmXUlMWjd0uSH7r7H3cvcva+79wWeAy5wdz0kIFkTtbFXdfxSCJp9oMzMFgOHgFUkSgV/cfdvhT642XkkJrEpBu5191vN7BYSjzovbbLvU8B3WwoEeqBMWivqA10inUFzD5S1FAg2ufvQ4H0JiUnsR8WTzXAUCKRVZs6EWbOO3D5jhur5paBEebL4UPKNux/Oaq5E2oMae0Va1FIgGG5m7wbLe8Cw5Hsze7c9MigShRp7RVrW0nwExZ6YjyA5J0FJynvNRyCxi9rrR429Ii0LNfpoPlEbQWHRyJsi2ZGt0UdF2l3k2blEpEUKBJLfsjCMs4g0T4FA8pt6/YjEToFA8pp6/YjEryTXGZDm/fkTY6nbfeRNr7isjEFPr8pBjtpXc71+1E4gkh0qEeS5dEGgue35Jmr3Tw3jLBI/BQKJVdRB30QkfgoEEit1/xTJfwoEEi91/xTJewoEEi91/xTJewoEea64LH0VSqbt+UbdP0Xyn7qP5rmO3kVU3T9F8p8GnRMRKQAadE5ERDJSIJBmRX0gTETynwKBNEsPhIl0fmosjtmfPzGW3YePY8PQqdQXd6Wo7iDDN91DWcnbHaIhOPWBsLXogTCRzkglgpglgsA3qS/uCkB9cVc2DP0muw8fl+OchaQHwkQ6PQWCmCVKAt0abasv7saGoVNzlKNW0gNhIp2eAkHMkiWBsNvzjR4IE+n8FAhiVlR3sFXb801zD4SJSOegB8pitvqMC4I2gg+qh4rqDjB80xzGPLc0hzkTkUKiB8pyqKzkbYZvmtNQAkj0GppDWcnbOc6ZiEiCuo/GbNDTqxgEjGm0dUJuMiMikoZKBCIiBU6BoJPTEBEi0pJYq4bMbALwE6AYWODutzX5/DvA1cBhoBa4yt3/EmeeCs3Yf/4aRe+8xRZgyLatbFm0mOOAsT0/BM89k+vsiUgeiK1EYGbFwN3AucApwKVmdkqT3dYBFe4+DPg1cHtc+SlURe+81artIlJ44iwRjAaq3f1lADNbBFwIbE7u4O5Ppuz/HPCVGPNTkMp219L7zTcb1ods2wpAba9eucqSiOSZOAPBR4CdKes1wOnN7P914PfpPjCza4BrAE466aRs5a/DqPnTayy75yXq6ospLqpj4tRTKT/1+FBpd5f1ZndZbyCoGhr8sYbPeseSWxHpaOJsLLY029I+vWZmXwEqgB+m+9zd57l7hbtX9O5dWLevmpWreOTuDdTVFwNQV1/MI3evp2Zl/o9cKiIdQ5wlghrgxJT1cuC1pjuZ2WeAm4Gz3f1AjPnpkJYt3k+dNx607rB3Y9ni/Vx7duuO1ZbqoD9/Yix1u48cV6i4rKxDDKMtIi2LMxC8CAw0s37Aq8Ak4LLUHcxsJPAzYIK7vxFjXjqsZEkg7PamisvKMs6HEOr8aYJAc9tFpOOJLRC4+2EzmwY8RqL76L3u/pKZ3QJUuftSElVBPYBfmRnAX939grjy1BEVF9WlvekXF9WFSt/91n9n06K91PsH8yFsGvlNzp/UI6v5FJGOK9bnCNx9ObC8ybbpKe8/E+f5O4OJlaU8smgvh1Oqh0rsAOdXhruRZ7NqSUQ6Jz1ZnOfKzx7L+deNaCgBFBfVcf51Iyg/e2yo9FGrlkSk89Ogcx1A+anHc+094bqLNhW1aklEOj+VCDq5iZWllFjjzlgldoCJlaWh0heXpZ+kPtN2Eel4VCLIc3NX7mBY+bGJGcJmzkzMIbxjNxtr9nDt2f1bTF9+9ljO77WLZff8qeGBtPOnjgj9QJq6iIp0fpqhLM+lzhk8ZkBvVlfXfrDev31+lUd5slnPIYjkB81Q1oEl5wie9uA6gPYPAhGfbNZzCCL5T1VD7aDq9SqWbF/SsH7RwIuo6JM2MB9p5kzGzJrF2mB17fTxMB2YMaNhfoE4qfupSOenQBCzfYf2ceOTN7Ln4J6GbU+/+jQrLl7BUSVHtXyAmTNZ/dVpTHtwHWunj2fULSvatUSg7qcinZ+qhmI2f9N8DtQ17rWz//B+5m+cHyp9ahsB0FBN1DDrWMwydTNV91ORzkMlgpgt3raY/XX7G23bX7efRdsWccOoG1pMv7FmzwclgBkzGtoMNtbsaZdSQdQnmwHe7jnwiLGOjntne6i0amwWiZ9KBDGrHFxJaXHjPvulxaVMGjwpVPprz+7/wQ0/aBMY078sVNfRbIj6ZPOe8hFsGPpN6os/GOtow9Bvsqd8RKj0amwWiZ9KBDGbMnQKv9r2q0algtKSUqYMm5LDXLVOlCeb1w+6ivom7Qn1xd1YP+gqzshG5kQkMgWCmHXv0p07P3XnEb2GQjUUdwJqbBbJfwoE7aCiT0X47qKdTDbGOlIbg0i81EYgsYo61lEiCBzZxvB2z4Gh0quNQaRlCgQSq6iNzRuGXUd9ceMH2uqLu7Fh2HVZz6tIoVLVkMQuSmNzfVGXVm1PR1VLIs1TiUDyWtQH2lS1JNIyBQLJa1HbGBIlgTRVS0OnZi2PIh2dqoZiFnU+gUIXdT6FZEkg7PZ0VLUknZ0CQcyGlR/7wdDRs2Y1DCCXHDtIWpbLqTozVS0N3zQnVHpVLUlHoEAQs9T5BNbS/vMJFLqoYyUlSwKpklVLY0LmIUqJAlSqkPipjSBuM2cyZkDvxDwCJOYTGDOgd7vMJSDRu69GrVqK2lgNKlVI/FQiiFuO5xOAiBPjdAK5rFrKRokC1E4h8VKJIGa5nk8gOTHOspeXNSzffurbvH/4/XY5f0cXtddS9hqr1QVW4qMSQcyyMZ9AlF/0zU2ME2Y+hEIXtddSUf2htA+/FdUfCp2HXLdTqETR+Zm75zoPrVJRUeFVVVW5zka72XdoH+N/Pb7RVJc9u/UMPdXlmIfG8N7B947YfnTXo1l96epQeSj0qqUoalauSt9YPalH6HaKu699IuNn1839dIvpV59xQVCi+CAPRXUHGL5pDmOeW9pi+i0fG5IxkAzZuqXF9Aok+cHM1rh72v+4KhHkuai/6CsHV/LA5gcaz4fQiolxIs+5TGEHkqglCoheqohaoshGF9q0gWS3SiT5QoEgz0Wd6jLqxDhRA1E+BJJcB6IojdUAn5/cPX2pYnK4LrBR2yk6QyDZffi4I9KXlbwdKpAUQiBSIMhzUX/RR50YJ2ogynUg6QyBqPzssQwoXsWWB9/H6kvwosMMuKwH5Z8IV7UUtUTR0QNJIgikTz8oRPpCCEQKBHkuG1NdRpkYJ2ogynUg6QyBaN+hfczY+S/sOT2lnaimJ2MOhzvG5yd353eL9lKfUqIosgN8PmSJoqjuYNqbflHdwVDpcx1ICj0QhRFr91Ezm2Bm28ys2sxuSvN5NzNbHHz+vJn1zXYeNow+k9VnXMCcKY/yQsXlzJnyaKLxbPSZodLPXbmDe3/7KLOnruCFisuZPXUF9/72Ueau3JHtrKaV/EU/8aMTG5Y7xt3RblNdThk6hW5NBm1rTSCqHFxJaXHjrpbZCiTtkb65QNIe6bNxjA+NOY0/DP0lhy1RAjhsh3h86IP0Oivcj4MR/7OQoibnL6o7wIj/WRgqfaaA0V6BJDuBqO0DF0ZNn42HElsSWyAws2LgbuBc4BTgUjM7pcluXwfedvcBwB3AD7Kdj78X9W64iKPX/KLhIv69qHeo9ANrN/PeY47VlzB6zS+w+hLee8wZVLs521nNqKJPBd8f+/2GpT3rt6MGolwHko4eiLJxjPmb5rPzmG0sOOO7zD3zWyw447v89ZitoQPJC7efyfLhCxsFkuXDF/Li7eE6rw6pnp82kAypDnf+qIGk0ANRGHGWCEYD1e7+srsfBBYBFzbZ50LgvuD9r4FzzMyymYmoF3HLE10pqW+cvqS+G5ufCP9AUEcXJRDlOpB09ECUjWNkI5i9cvTmRoHklaM3h07/r9fs4uGh8xoFkoeHzuNfr9kVKv2A7XPSBpIB28NVzQzfdE/a9MM33RMqfUcPRGHE2UbwEWBnynoNcHqmfdz9sJntAXoBjVpGzOwa4BqAk046qVWZOG3dQ4xe84uG9et+dg4AL5z2NWBCi+lHv/BgM+k/16q8FHotdDoAAAkzSURBVKoobRRRG7ujpo/aRpONNp6ox4jazpOV9HUPsOCM7zZK/9XBXw2VfvOPP83jqxfymZeuosS7JKq2hi/ks988h8+GSN/daxi+aU6TOvY5dPeaUOcfsH0O1QOvPeI5jAHb5xLmHjJ80z0Zn+MIkz5qG00YsT1QZmZfBj7n7lcH618FRrv79Sn7vBTsUxOs7wj2eTPTcVv7QNmcKY82XMTrfnYOd3/jv4HERfzm/Jb/EWZPfQyr73JEei86xLR7FAgKQa57DUU9RtSHEgs9/U/W/oTHV69uHIg+fi+fHXNWqA4H608fxT4rP6Kxt7vXMOL5tS2mf+pTF7FlwNVHBJIh1QsY9+SSZlI2lqsHymqAE1PWy4HXMuxTY2YlwLHAW9nMRNRoPOTTB/nTE/WNqocOFx1g6KcPZzObkseilGiykT7qMXJdquro6ZMlstQSTc9uPUOXyAY9/XQQiL73QfpzerLi4mdCpR+94n7umn8NZ2/6akMg+uPIB7lizgOh0ocRZ4mgBPgzcA7wKvAicJm7v5Syz3XAUHe/1swmAV9y90uaO25rSwQbRp8ZNBhP5bR1D7Fm5KUM33QP/1Bfy/AXnm0x/dyVO+j6znb2PVbE6Bd+yQujJ9P9c/Uc7DlQM4yJFIhclwqzUapsrkQQ61hDZnYecCdQDNzr7rea2S1AlbsvNbNS4H5gJImSwCR3f7m5YxbaWEMiItmQs7GG3H05sLzJtukp7/cDX44zDyIi0jzNRyAiUuAUCERECpwCgYhIgVMgEBEpcB1uhjIzqwX+0sbkZTR5ajnPKH/RKH/R5Xselb+2O9nd0w6y1uECQRRmVpWp+1Q+UP6iUf6iy/c8Kn/xUNWQiEiBUyAQESlwhRYI5uU6Ay1Q/qJR/qLL9zwqfzEoqDYCERE5UqGVCEREpAkFAhGRAtcpA4GZTTCzbWZWbWY3pfm8m5ktDj5/3sz6tmPeTjSzJ81si5m9ZGbfSrPPODPbY2brg2V6umPFmMdXzGxTcO4jhnq1hLuC67fRzEa1Y94Gp1yX9Wb2rpnd2GSfdr9+Znavmb1hZn9K2fYhM/uDmW0PXo/LkPbyYJ/tZnZ5O+Xth2a2Nfj3+y8z65khbbN/CzHncaaZvZry73hehrTN/n+PMX+LU/L2ipmtz5C2Xa5hJO7eqRYSQ17vAD4KdAU2AKc02WcqMDd4PwlY3I75Ox4YFbw/msScDU3zNw5YlsNr+ApQ1szn5wG/Bww4A3g+h//Wr5N4UCan1w/4JDAK+FPKttuBm4L3NwE/SJPuQ8DLwetxwfvj2iFv44GS4P0P0uUtzN9CzHmcCXw3xN9As//f48pfk8//A5iey2sYZemMJYLRQLW7v+zuB4FFwIVN9rkQuC94/2vgHDOz9sicu+9y97XB+/eALSTmbu5ILgR+4QnPAT3N7Pgc5OMcYIe7t/VJ86xx9z9y5Ox6qX9n9wFfSJP0c8Af3P0td38b+ANhps6LmDd3X+HuyWn2niMxg2DOZLh+YYT5/x5Zc/kL7h2XAA9l+7ztpTMGgo8AO1PWazjyRtuwT/CfYQ/Qq11ylyKokhoJPJ/m4zPNbIOZ/d7MPt6uGQMHVpjZGjO7Js3nYa5xe5hE5v98ubx+Sf/L3XdB4gcA8OE0++TDtbyKRAkvnZb+FuI2Lai+ujdD1Vo+XL+xwN/cfXuGz3N9DVvUGQNBul/2TfvIhtknVmbWA1gC3Oju7zb5eC2J6o7hwE+Bh9szb8BZ7j4KOBe4zsw+2eTzfLh+XYELgF+l+TjX1681cnotzexm4DDwywy7tPS3EKc5QH9gBLCLRPVLUzn/WwQupfnSQC6vYSidMRDUACemrJcDr2XaxxJzKx9L24qlbWJmXUgEgV+6+2+afu7u77r73uD9cqCLmZW1V/7c/bXg9Q3gv0gUv1OFucZxOxdY6+5/a/pBrq9fir8lq8yC1zfS7JOzaxk0TE8EJntQmd1UiL+F2Lj739y9zt3rgfkZzp3Tv8Xg/vElYHGmfXJ5DcPqjIHgRWCgmfULfjVOApY22WcpkOydcTHwRKb/CNkW1Cf+P2CLu/84wz59km0WZjaaxL/Tm+2Uv38ws6OT70k0Kv6pyW5Lga8FvYfOAPYkq0DaUcZfYbm8fk2k/p1dDvw2zT6PAePN7Lig6mN8sC1WZjYB+GfgAnffl2GfMH8LceYxtd3pixnOHeb/e5w+A2x195p0H+b6GoaW69bqOBYSvVr+TKI3wc3BtltI/NEDlJKoUqgGXgA+2o55+wSJoutGYH2wnAdcC1wb7DMNeIlED4jngDHtmL+PBufdEOQhef1S82fA3cH13QRUtPO/b3cSN/ZjU7bl9PqRCEq7gEMkfqV+nUS7038D24PXDwX7VgALUtJeFfwtVgNXtlPeqknUrSf/BpO96E4Aljf3t9CO1+/+4O9rI4mb+/FN8xisH/H/vT3yF2xfmPy7S9k3J9cwyqIhJkREClxnrBoSEZFWUCAQESlwCgQiIgVOgUBEpMApEIiIFDgFApEMzOxmS4wQuzEYOfJ0M7vRzLrnOm8i2aTuoyJpmNmZwI+Bce5+IHgyuSuwmsRzE7tzmkGRLFKJQCS944Hd7n4AILjxX0ziYaEnzexJADMbb2bPmtlaM/tVMIZUcgz6H5jZC8EyINj+ZTP7UzAg3h9z89VEGlOJQCSN4Ib+NImnmB8nMWfFSjN7haBEEJQSfgOc6+5/N7N/Brq5+y3BfvPd/VYz+xpwibtPNLNNwAR3f9XMerr7Ozn5giIpVCIQScMTg9adBlwD1AKLzeyKJrudAZwCPBPMTnU5cHLK5w+lvJ4ZvH8GWGhmU0hMqiKScyW5zoBIvnL3OuAp4Kngl3zTaSSNxKQyl2Y6RNP37n6tmZ0OnA+sN7MR7p6LAfFEGqhEIJKGJeZGHpiyaQTwF+A9ElOMQmJAu7NS6v+7m9mglDSVKa/PBvv0d/fn3X06sJvGQyiL5IRKBCLp9QB+aolJ3Q+TGK3zGhLDX//ezHa5+6eC6qKHzKxbkO7fSIyECdDNzJ4n8YMrWWr4YRBgjMSIpBva5duINEONxSIxSG1UznVeRFqiqiERkQKnEoGISIFTiUBEpMApEIiIFDgFAhGRAqdAICJS4BQIREQK3P8Hg0SNn1Lm7dgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "P = np.matrix([[1., 0., 0., 0., 0., 0.],\n",
    "               [1./4, 1./2, 0., 1./4, 0., 0.],\n",
    "               [0., 0., 0., 1., 0., 0.],\n",
    "               [1./16, 1./4, 1./8, 1./4, 1./4, 1./16],\n",
    "               [0., 0., 0., 1./4, 1./2, 1./4],\n",
    "               [0., 0., 0., 0., 0., 1.]])\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "\n",
    "P = np.matrix([[1., 0., 0., 0., 0., 0.],\n",
    "               [1./4, 1./2, 0., 1./4, 0., 0.],\n",
    "               [0., 0., 0., 1., 0., 0.],\n",
    "               [1./16, 1./4, 1./8, 1./4, 1./4, 1./16],\n",
    "               [0., 0., 0., 1./4, 1./2, 1./4],\n",
    "               [0., 0., 0., 0., 0., 1.]])\n",
    "\n",
    "v = np.matrix([[0, 0, 1, 0, 0, 0]])\n",
    "\n",
    "# Get the data\n",
    "plot_data = []\n",
    "for step in range(20):\n",
    "    result = v * P**step\n",
    "    plot_data.append(np.array(result).flatten())\n",
    "\n",
    "# Convert the data format\n",
    "plot_data = np.array(plot_data)\n",
    "\n",
    "# Create the plot\n",
    "pyplot.figure(1)\n",
    "pyplot.xlabel('Steps')\n",
    "pyplot.ylabel('Probability')\n",
    "lines = []\n",
    "for i, shape in zip(range(6), ['x', 'h', 'H', 's', '8', 'r+']):\n",
    "    line, = pyplot.plot(plot_data[:, i], shape, label=\"S%i\" % (i+1))\n",
    "    lines.append(line)\n",
    "pyplot.legend(handles=lines, loc=1)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot, we can observe that the probabilities of reaching states S1 and S6 initially increased and attained a maximum around 0.5 while the probabilities of all other states decreased and became 0. Therefore, if we start from state 3, and go on taking steps we will eventually end either in state S1 or state S6 with both having equal probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of Markov Chain Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a simple example, take a look at predicting the weather to understand this representation better. Consider that there are three possible states of the random variable Weather = {Sunny, Rainy, Snowy}. \n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1200/1*udOn3pR6SqrKU37KujfdPg.png\" style=\"height: 250px;\" />  \n",
    "\n",
    "In the above Markov chain, consider that the observed state of the current random variable is Sunny. Then, the probability that the random variable at the next time instance will also take the value Sunny is 0.8. It could also take the value Rainy with a probability of 0.19, or Snowy with a probability of 0.01. One thing to note here is that the sum of all the probability values on all the outward edges from any state should equal 1, since it’s an exhaustive event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "class MarkovChain(object):\n",
    "    def __init__(self, transition_prob):\n",
    "        \"\"\"\n",
    "        Initialize the MarkovChain instance.\n",
    " \n",
    "        Parameters\n",
    "        ----------\n",
    "        transition_prob: dict\n",
    "            A dict object representing the transition \n",
    "            probabilities in Markov Chain. \n",
    "            Should be of the form: \n",
    "                {'state1': {'state1': 0.1, 'state2': 0.4}, \n",
    "                 'state2': {...}}\n",
    "        \"\"\"\n",
    "        self.transition_prob = transition_prob\n",
    "        self.states = list(transition_prob.keys())\n",
    " \n",
    "    def next_state(self, current_state):\n",
    "        \"\"\"\n",
    "        Returns the state of the random variable at the next time \n",
    "        instance.\n",
    " \n",
    "        Parameters\n",
    "        ----------\n",
    "        current_state: str\n",
    "            The current state of the system.\n",
    "        \"\"\"\n",
    "        return np.random.choice(\n",
    "            self.states, \n",
    "            p=[self.transition_prob[current_state][next_state] \n",
    "               for next_state in self.states]\n",
    "        )\n",
    "    \n",
    "    def generate_states(self, current_state, no=10):\n",
    "        \"\"\"\n",
    "        Generates the next states of the system.\n",
    " \n",
    "        Parameters\n",
    "        ----------\n",
    "        current_state: str\n",
    "            The state of the current random variable.\n",
    " \n",
    "        no: int\n",
    "            The number of future states to generate.\n",
    "        \"\"\"\n",
    "        future_states = []\n",
    "        for i in range(no):\n",
    "            next_state = self.next_state(current_state)\n",
    "            future_states.append(next_state)\n",
    "            current_state = next_state\n",
    "        return future_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Snowy',\n",
       " 'Snowy',\n",
       " 'Snowy',\n",
       " 'Rainy',\n",
       " 'Rainy',\n",
       " 'Rainy',\n",
       " 'Rainy',\n",
       " 'Sunny',\n",
       " 'Sunny',\n",
       " 'Sunny']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_prob = {'Sunny': {'Sunny': 0.8, 'Rainy': 0.19, \n",
    " 'Snowy': 0.01},\n",
    " 'Rainy': {'Sunny': 0.2, 'Rainy': 0.7,\n",
    " 'Snowy': 0.1},\n",
    " 'Snowy': {'Sunny': 0.1, 'Rainy': 0.2,\n",
    " 'Snowy': 0.7}}\n",
    "\n",
    "weather_chain = MarkovChain(transition_prob=transition_prob)\n",
    "weather_chain.next_state(current_state='Sunny')\n",
    "weather_chain.generate_states(current_state='Snowy', no=10)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questionnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Suppose that there is a coin purse containing five quarters (each worth 25¢), five dimes (each worth 10¢), and five nickels (each worth 5¢), and one by one, coins are randomly drawn from the purse and are set on a table. If Xn represents the total value of the coins set on the table after n draws, with X0 = 0, then is the sequence { Xn : n ∈ N } a Markov process?** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Predicting the weather. The weather on day 0 (today) is known to be sunny. There are two kinds of weather - \"sunny\" \"rainy\". Based on this information predict tomorrow's and day after tomorrow's weather**  \n",
    "\n",
    "![alt text](https://upload.wikimedia.org/wikipedia/commons/7/7a/Markov_Chain_weather_model_matrix_as_a_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Solutions](https://github.com/ebi-byte/kt/blob/master/supervised_ML/Markov%20Chain%20Solutions.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
