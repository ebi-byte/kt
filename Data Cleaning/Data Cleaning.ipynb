{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured vs unstructured data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structured data is highly-organized and formatted in a way so it's easily searchable in relational databases. Unstructured data has no pre-defined format or organization, making it much more difficult to collect, process, and analyze.  \n",
    "In addition to being collected, processed, and analyzed in different ways, structured and unstructured data will reside in completely different databases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unstructured data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unstructured data is the data which does not conforms to a data model and has no easily identifiable structure such that it can not be used by a computer program easily. Unstructured data is not organised in a pre-defined manner or does not have a pre-defined data model, thus it is not a good fit for a mainstream relational database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Characteristics of Unstructured Data: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "•Data neither conforms to a data model nor has any structure.  \n",
    "•Data can not be stored in the form of rows and columns as in Databases.  \n",
    "•Data does not follows any semantic or rules.  \n",
    "•Data lacks any particular format or sequence.  \n",
    "•Data has no easily identifiable structure.  \n",
    "•Due to lack of identifiable structure, it can not used by computer programs easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sources of Unstructured Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "•Web pages  \n",
    "•Images (JPEG, GIF, PNG, etc.)   \n",
    "•Videos  \n",
    "•Memos  \n",
    "•Reports  \n",
    "•Word documents and PowerPoint persentations   \n",
    "•Surveys  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advantages of Unstructured Data: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "•Its supports the data which lacks a proper format or sequence  \n",
    "•The data is not constrained by a fixed schema  \n",
    "•Very Flexible due to absence of schema  \n",
    "•Data is portable  \n",
    "•It is very scalable   \n",
    "•It can deal easily with the heterogeneity of sources  \n",
    "•These type of data have a variety of business intelligence and analytics applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Disadvantages Of Unstructured data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "•It is difficult to store and manage unstructured data due to lack of schema and structure.  \n",
    "•Indexing the data is difficult and error prone due to unclear structure and not having pre-defined attributes. Due to which search results are not very accurate.  \n",
    "•Ensuring security to data is difficult task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting information from unstructured Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unstructured data do not have any structure. So it can not easily interpreted by conventional algorithms. It is also difficult to tag and index unstructured data. So extracting information from them is tough job. Here are possible solutions:  \n",
    "  \n",
    "•Taxonomies or classification of data helps in organising data in hierarchical structure. Which will make search process easy.  \n",
    "•Data can be stored in virtual repository and be automatically tagged. For example Documentum.   \n",
    "•Use of application platforms like XOLAP.  \n",
    "XOLAP helps in extracting information from e-mails and XML based documents .  \n",
    "•Use of various data mining tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structured data is the data which conforms to a data model, has a well define structure, follows a consistent order and can be easily accessed and used by a person or a computer program. \n",
    "\n",
    "Structured data is usually stored in well-defined schemas such as Databases. It is generally tabular with column and rows that clearly define its attributes. \n",
    "\n",
    "SQL (Structured Query language) is often used to manage structured data stored in databases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Characteristics of Structured Data: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "•Data conforms to a data model and has easily identifiable structure  \n",
    "•Data is stored in the form of rows and columns  \n",
    "Example : Database  \n",
    "•Data is well organised so, Definition, Format and Meaning of data is explicitly known  \n",
    "•Data resides in fixed fields within a record or file  \n",
    "•Similar entities are grouped together to form relations or classes  \n",
    "•Entities in the same group have same attributes  \n",
    "•Easy to access and query, So data can be easily used by other programs  \n",
    "•Data elements are addressable, so efficient to analyse and process  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sources of Structured Data: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "•SQL Databases  \n",
    "•Spreadsheets such as Excel  \n",
    "•OLTP Systems  \n",
    "•Online forms  \n",
    "•Sensors such as GPS or RFID tags  \n",
    "•Network and Web server logs  \n",
    "•Medical devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advantages of Structured Data: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "•Structured data have a well defined structure that helps in easy storage and access of data  \n",
    "•Data can be indexed based on text string as well as attributes. This makes search operation hassle-free   \n",
    "•Data mining is easy i.e knowledge can be easily extracted from data  \n",
    "•Operations such as Updating and deleting is easy due to well structured form of data  \n",
    "•Business Intelligence operations such as Data warehousing can be easily undertaken  \n",
    "•Easily scalable in case there is an increment of data  \n",
    "•Ensuring security to data is easy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structured data accounts for only about 20% of data but because of its high degree of organisation and performance make it foundation of Big data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning in Pyton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning is one of the important parts of machine learning. It plays a significant part in building a model. It surely isn’t the fanciest part of machine learning and at the same time, there aren’t any hidden tricks or secrets to uncover. However, proper data cleaning can make or break your project. Professional data scientists usually spend a very large portion of their time on this step.\n",
    "Because of the belief that, “Better data beats fancier algorithms”.\n",
    "If we have a well-cleaned dataset, we can get desired results even with a very simple algorithm, which can prove very beneficial at times.\n",
    "\n",
    "Obviously, different types of data will require different types of cleaning. However, this systematic approach can always serve as a good starting point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps involved in Data Cleaning: \n",
    "    1. Removal of unwanted observations  \n",
    "    2. Fixing Structural errors  \n",
    "    3. Managing Unwanted outliers  \n",
    "    4. Handling missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removal of unwanted observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This includes deleting duplicate/ redundant or irrelevant values from our dataset. Duplicate observations most frequently arise during data collection and Irrelevant observations are those that don’t actually fit the specific problem that we’re trying to solve.  \n",
    "•Redundant observations alter the efficiency by a great extent as the data repeats and may add towards the correct side or towards the incorrect side, thereby producing unfaithful results.   \n",
    "•Irrelevant observations are any type of data that is of no use to us and can be removed directly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixing Structural errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The errors that arise during measurement, transfer of data or other similar situations are called structural errors. Structural errors include typos in the name of features, same attribute with different name, mislabeled classes, i.e. separate classes that should really be the same or inconsistent capitalization.   \n",
    "•For example, the model will treat America and america as different classes or values, though they represent the same value or red, yellow and red-yellow as different classes or attributes, though one class can be included in other two classes. So, these are some structural errors that make our model inefficient and gives poor quality results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Managing Unwanted outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers can cause problems with certain types of models. For example, linear regression models are less robust to outliers than decision tree models. Generally, we should not remove outliers until we have a legitimate reason to remove them. Sometimes, removing them improves performance, sometimes not. So, one must have a good reason to remove the outlier, such as suspicious measurements that are unlikely to be the part of real data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data is a deceptively tricky issue in machine learning. We cannot just ignore or remove the missing observation. They must be handled carefully as they can be an indication of something important. The two most common ways to deal with missing data are: \n",
    "    1. Dropping observations with missing values.  \n",
    "Dropping missing values is sub-optimal because when you drop observations, you drop information.  \n",
    "•The fact that the value was missing may be informative in itself.  \n",
    "•Plus, in the real world, we often need to make predictions on new data even if some of the features are missing!  \n",
    "    2. Imputing the missing values from past observations.  \n",
    "Imputing missing values is sub-optimal because the value was originally missing but we filled it in, which always leads to a loss in information, no matter how sophisticated our imputation method is.  \n",
    "•Again, “missingness” is almost always informative in itself, and we should tell your algorithm if a value was missing.  \n",
    "•Even if we build a model to impute our values, we’re not adding any real information. We’re just reinforcing the patterns already provided by other features. \n",
    "\n",
    "Both of these approaches are sub-optimal because dropping an observation means dropping information, thereby reducing data and imputing values also is sub-optimal as we fil the values that were not present in the actual dataset, which leads to a loss of information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data is like missing a puzzle piece. If we drop it, that’s like pretending the puzzle slot isn’t there. If we impute it, that’s like trying to squeeze in a piece from somewhere else in the puzzle.\n",
    " So, missing data is always informative and indication of something important. And we must aware our algorithm of missing data by flagging it. By using this technique of flagging and filling, we are essentially allowing the algorithm to estimate the optimal constant for missingness, instead of just filling it in with the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between data found in many tutorials and data in the real world is that real-world data is rarely clean and homogeneous. In particular, many interesting datasets will have some amount of data missing. To make matters even more complicated, different data sources may indicate missing data in different ways.\n",
    "\n",
    "We will discuss some general considerations for missing data, discuss how Pandas chooses to represent it, and demonstrate some built-in Pandas tools for handling missing data in Python. Here we'll refer to missing data in general as null, NaN, or NA values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of schemes that have been developed to indicate the presence of missing data in a table or DataFrame. Generally, they revolve around one of two strategies: using a mask that globally indicates missing values, or choosing a sentinel value that indicates a missing entry.\n",
    "\n",
    "In the masking approach, the mask might be an entirely separate Boolean array, or it may involve appropriation of one bit in the data representation to locally indicate the null status of a value.\n",
    "\n",
    "In the sentinel approach, the sentinel value could be some data-specific convention, such as indicating a missing integer value with -9999 or some rare bit pattern, or it could be a more global convention, such as indicating a missing floating-point value with NaN (Not a Number), a special value which is part of the IEEE floating-point specification.\n",
    "\n",
    "None of these approaches is without trade-offs: use of a separate mask array requires allocation of an additional Boolean array, which adds overhead in both storage and computation. A sentinel value reduces the range of valid values that can be represented, and may require extra (often non-optimized) logic in CPU and GPU arithmetic. Common special values like NaN are not available for all data types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas chose to use sentinels for missing data, and further chose to use two already-existing Python null values: the special floating-point NaN value, and the Python None object. This choice has some side effects, as we will see, but in practice ends up being a good compromise in most cases of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### None: Pythonic missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first sentinel value used by Pandas is None, a Python singleton object that is often used for missing data in Python code. Because it is a Python object, None cannot be used in any arbitrary NumPy/Pandas array, but only in arrays with data type 'object' (i.e., arrays of Python objects):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, None, 3, 4], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "vals1 = np.array([1, None, 3, 4])\n",
    "vals1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dtype=object means that the best common type representation NumPy could infer for the contents of the array is that they are Python objects. While this kind of object array is useful for some purposes, any operations on the data will be done at the Python level, with much more overhead than the typically fast operations seen for arrays with native types:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of Python objects in an array also means that if we perform aggregations like sum() or min() across an array with a None value, we will generally get an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-30a3fc8c6726>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvals1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[0;32m     34\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[0;32m     35\u001b[0m          initial=_NoValue):\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "vals1.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reflects the fact that addition between an integer and None is undefined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NaN: Missing numerical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other missing data representation, NaN (acronym for Not a Number), is different; it is a special floating-point value recognized by all systems that use the standard IEEE floating-point representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals2 = np.array([1, np.nan, 3, 4]) \n",
    "vals2.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that NumPy chose a native floating-point type for this array: this means that unlike the object array from before, this array supports fast operations pushed into compiled code. We should be aware that NaN is a bit like a data virus–it infects any other object it touches. Regardless of the operation, the result of arithmetic with NaN will be another NaN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 + np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0 *  np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this means that aggregates over the values are well defined (i.e., they don't result in an error) but not always useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(nan, nan, nan)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals2.sum(), vals2.min(), vals2.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy does provide some special aggregations that will ignore these missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.0, 1.0, 4.0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nansum(vals2), np.nanmin(vals2), np.nanmax(vals2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that NaN is specifically a floating-point value; there is no equivalent NaN value for integers, strings, or other types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NaN and None both have their place, and Pandas is built to handle the two of them nearly interchangeably, converting between them where appropriate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    NaN\n",
       "2    2.0\n",
       "3    NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([1, np.nan, 2, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For types that don't have an available sentinel value, Pandas automatically type-casts when NA values are present. For example, if we set a value in an integer array to np.nan, it will automatically be upcast to a floating-point type to accommodate the NA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "dtype: int32"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.Series(range(2), dtype=int)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    NaN\n",
       "1    1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0] = None\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that in addition to casting the integer array to floating point, Pandas automatically converts the None to a NaN value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this type of magic may feel a bit hackish compared to the more unified approach to NA values in domain-specific languages like R, the Pandas sentinel/casting approach works quite well in practice and only rarely causes issues.\n",
    "\n",
    "The following table lists the upcasting conventions in Pandas when NA values are introduced:\n",
    "\n",
    "|Typeclass|Conversion When Storing NAs|NA Sentinel Value|\n",
    "|:------|:------|:------|\n",
    "|floating |No change| np.nan |\n",
    "|object |No change| None or np.nan |\n",
    "|integer |Cast to float64| np.nan |\n",
    "|boolean |Cast to object| None or np.nan |\n",
    "\n",
    "Keep in mind that in Pandas, string data is always stored with an object dtype."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operating on Null Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen, Pandas treats None and NaN as essentially interchangeable for indicating missing or null values. To facilitate this convention, there are several useful methods for detecting, removing, and replacing null values in Pandas data structures. They are:  \n",
    "•isnull(): Generate a boolean mask indicating missing values  \n",
    "•notnull(): Opposite of isnull()  \n",
    "•dropna(): Return a filtered version of the data  \n",
    "•fillna(): Return a copy of the data with missing values filled or imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1      NaN\n",
       "2    hello\n",
       "3     None\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.Series([1, np.nan, 'hello', None])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1     True\n",
       "2    False\n",
       "3     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Boolean masks can be used directly as a Series or DataFrame index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "2    hello\n",
       "dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The isnull() and notnull() methods produce similar Boolean results for DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the masking used before, there are the convenience methods, dropna() (which removes NA values) and fillna() (which fills in NA values). For a Series, the result is straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "2    hello\n",
       "dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a DataFrame, there are more options. Consider the following DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1  2\n",
       "0  1.0  NaN  2\n",
       "1  2.0  3.0  5\n",
       "2  NaN  4.0  6"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([[1,      np.nan, 2],\n",
    "                   [2,      3,      5],\n",
    "                   [np.nan, 4,      6]])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot drop single values from a DataFrame; we can only drop full rows or full columns. Depending on the application, you might want one or the other, so dropna() gives a number of options for a DataFrame.\n",
    "\n",
    "By default, dropna() will drop all rows in which any null value is present:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1  2\n",
       "1  2.0  3.0  5"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can drop NA values along a different axis; axis=1 drops all columns containing a null value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   2\n",
       "0  2\n",
       "1  5\n",
       "2  6"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this drops some good data as well; we might rather be interested in dropping rows or columns with all NA values, or a majority of NA values. This can be specified through the how or thresh parameters, which allow fine control of the number of nulls to allow through.\n",
    "\n",
    "The default is how='any', such that any row or column (depending on the axis keyword) containing a null value will be dropped. We can also specify how='all', which will only drop rows/columns that are all null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1  2   3\n",
       "0  1.0  NaN  2 NaN\n",
       "1  2.0  3.0  5 NaN\n",
       "2  NaN  4.0  6 NaN"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[3] = np.nan\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1  2\n",
       "0  1.0  NaN  2\n",
       "1  2.0  3.0  5\n",
       "2  NaN  4.0  6"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(axis='columns', how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For finer-grained control, the thresh parameter lets us specify a minimum number of non-null values for the row/column to be kept:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1  2   3\n",
       "1  2.0  3.0  5 NaN"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(axis='rows', thresh=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the first and last row have been dropped, because they contain only two non-null values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes rather than dropping NA values, we'd rather replace them with a valid value. This value might be a single number like zero, or it might be some sort of imputation or interpolation from the good values. We could do this in-place using the isnull() method as a mask, but because it is such a common operation Pandas provides the fillna() method, which returns a copy of the array with the null values replaced.\n",
    "\n",
    "Consider the following Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    1.0\n",
       "b    NaN\n",
       "c    2.0\n",
       "d    NaN\n",
       "e    3.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.Series([1, np.nan, 2, None, 3], index=list('abcde'))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fill NA entries with a single value, such as zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    1.0\n",
       "b    0.0\n",
       "c    2.0\n",
       "d    0.0\n",
       "e    3.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify a forward-fill to propagate the previous value forward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    1.0\n",
       "b    1.0\n",
       "c    2.0\n",
       "d    2.0\n",
       "e    3.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward-fill\n",
    "data.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can specify a back-fill to propagate the next values backward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    1.0\n",
       "b    2.0\n",
       "c    2.0\n",
       "d    3.0\n",
       "e    3.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# back-fill\n",
    "data.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For DataFrames, the options are similar, but we can also specify an axis along which the fills take place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1  2   3\n",
       "0  1.0  NaN  2 NaN\n",
       "1  2.0  3.0  5 NaN\n",
       "2  NaN  4.0  6 NaN"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3\n",
       "0  1.0  1.0  2.0  2.0\n",
       "1  2.0  3.0  5.0  5.0\n",
       "2  NaN  4.0  6.0  6.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fillna(method='ffill', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that if a previous value is not available during a forward fill, the NA value remains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Missing Data with Python on Pima Indians Diabetes Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pima Indians Diabetes Dataset involves predicting the onset of diabetes within 5 years in Pima Indians given medical details.  \n",
    "\n",
    "It is a binary (2-class) classification problem. There are 768 observations with 8 input variables and 1 output variable. The variable names are as follows:  \n",
    "0. Number of times pregnant.  \n",
    "1. Plasma glucose concentration after 2 hours in an oral glucose tolerance test.  \n",
    "2. Diastolic blood pressure (mm Hg).  \n",
    "3. Triceps skinfold thickness (mm).  \n",
    "4. 2-Hour serum insulin (mu U/ml).  \n",
    "5. Body mass index (weight in kg/(height in m)^2).  \n",
    "6. Diabetes pedigree function.  \n",
    "7. Age (years).   \n",
    "8. Class variable (0 or 1).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is known to have missing values.\n",
    "\n",
    "Specifically, there are missing observations for some columns that are marked as a zero value.\n",
    "\n",
    "We can corroborate this by the definition of those columns and the domain knowledge that a zero value is invalid for those measures, e.g. a zero for body mass index or blood pressure is invalid.\n",
    "\n",
    "We can use plots and summary statistics to help identify missing or corrupt data.\n",
    "\n",
    "We can load the dataset as a Pandas DataFrame and print summary statistics on each attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1   2   3    4     5      6   7  8\n",
       "0  6  148  72  35    0  33.6  0.627  50  1\n",
       "1  1   85  66  29    0  26.6  0.351  31  0\n",
       "2  8  183  64   0    0  23.3  0.672  32  1\n",
       "3  1   89  66  23   94  28.1  0.167  21  0\n",
       "4  0  137  40  35  168  43.1  2.288  33  1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>768.0</td>\n",
       "      <td>3.845052</td>\n",
       "      <td>3.369578</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>768.0</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>0.000</td>\n",
       "      <td>99.00000</td>\n",
       "      <td>117.0000</td>\n",
       "      <td>140.25000</td>\n",
       "      <td>199.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>768.0</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>0.000</td>\n",
       "      <td>62.00000</td>\n",
       "      <td>72.0000</td>\n",
       "      <td>80.00000</td>\n",
       "      <td>122.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>768.0</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>23.0000</td>\n",
       "      <td>32.00000</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>768.0</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>30.5000</td>\n",
       "      <td>127.25000</td>\n",
       "      <td>846.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>768.0</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.000</td>\n",
       "      <td>27.30000</td>\n",
       "      <td>32.0000</td>\n",
       "      <td>36.60000</td>\n",
       "      <td>67.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>768.0</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.24375</td>\n",
       "      <td>0.3725</td>\n",
       "      <td>0.62625</td>\n",
       "      <td>2.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>768.0</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>21.000</td>\n",
       "      <td>24.00000</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>41.00000</td>\n",
       "      <td>81.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>768.0</td>\n",
       "      <td>0.348958</td>\n",
       "      <td>0.476951</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count        mean         std     min       25%       50%        75%  \\\n",
       "0  768.0    3.845052    3.369578   0.000   1.00000    3.0000    6.00000   \n",
       "1  768.0  120.894531   31.972618   0.000  99.00000  117.0000  140.25000   \n",
       "2  768.0   69.105469   19.355807   0.000  62.00000   72.0000   80.00000   \n",
       "3  768.0   20.536458   15.952218   0.000   0.00000   23.0000   32.00000   \n",
       "4  768.0   79.799479  115.244002   0.000   0.00000   30.5000  127.25000   \n",
       "5  768.0   31.992578    7.884160   0.000  27.30000   32.0000   36.60000   \n",
       "6  768.0    0.471876    0.331329   0.078   0.24375    0.3725    0.62625   \n",
       "7  768.0   33.240885   11.760232  21.000  24.00000   29.0000   41.00000   \n",
       "8  768.0    0.348958    0.476951   0.000   0.00000    0.0000    1.00000   \n",
       "\n",
       "      max  \n",
       "0   17.00  \n",
       "1  199.00  \n",
       "2  122.00  \n",
       "3   99.00  \n",
       "4  846.00  \n",
       "5   67.10  \n",
       "6    2.42  \n",
       "7   81.00  \n",
       "8    1.00  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are columns that have a minimum value of zero (0). On some columns, a value of zero does not make sense and indicates an invalid or missing value.\n",
    "\n",
    "Specifically, the following columns have an invalid zero minimum value:  \n",
    "•1: Plasma glucose concentration  \n",
    "•2: Diastolic blood pressure  \n",
    "•3: Triceps skinfold thickness  \n",
    "•4: 2-Hour serum insulin  \n",
    "•5: Body mass index  \n",
    "\n",
    "Let’ confirm this by looking at the raw data, the example prints the first 20 rows of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0.191</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>168</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.537</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>139</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>1.441</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>846</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.398</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>166</td>\n",
       "      <td>72</td>\n",
       "      <td>19</td>\n",
       "      <td>175</td>\n",
       "      <td>25.8</td>\n",
       "      <td>0.587</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.484</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>84</td>\n",
       "      <td>47</td>\n",
       "      <td>230</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0.551</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>107</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>83</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.183</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>70</td>\n",
       "      <td>30</td>\n",
       "      <td>96</td>\n",
       "      <td>34.6</td>\n",
       "      <td>0.529</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1   2   3    4     5      6   7  8\n",
       "0    6  148  72  35    0  33.6  0.627  50  1\n",
       "1    1   85  66  29    0  26.6  0.351  31  0\n",
       "2    8  183  64   0    0  23.3  0.672  32  1\n",
       "3    1   89  66  23   94  28.1  0.167  21  0\n",
       "4    0  137  40  35  168  43.1  2.288  33  1\n",
       "5    5  116  74   0    0  25.6  0.201  30  0\n",
       "6    3   78  50  32   88  31.0  0.248  26  1\n",
       "7   10  115   0   0    0  35.3  0.134  29  0\n",
       "8    2  197  70  45  543  30.5  0.158  53  1\n",
       "9    8  125  96   0    0   0.0  0.232  54  1\n",
       "10   4  110  92   0    0  37.6  0.191  30  0\n",
       "11  10  168  74   0    0  38.0  0.537  34  1\n",
       "12  10  139  80   0    0  27.1  1.441  57  0\n",
       "13   1  189  60  23  846  30.1  0.398  59  1\n",
       "14   5  166  72  19  175  25.8  0.587  51  1\n",
       "15   7  100   0   0    0  30.0  0.484  32  1\n",
       "16   0  118  84  47  230  45.8  0.551  31  1\n",
       "17   7  107  74   0    0  29.6  0.254  31  1\n",
       "18   1  103  30  38   83  43.3  0.183  33  0\n",
       "19   1  115  70  30   96  34.6  0.529  32  1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 20 rows of data\n",
    "dataset.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see 0 values in the columns 2, 3, 4, and 5.  \n",
    "We can get a count of the number of missing values on each of these columns. We can do this by marking all of the values in the subset of the DataFrame we are interested in that have zero values as True. We can then count the number of true values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      5\n",
       "2     35\n",
       "3    227\n",
       "4    374\n",
       "5     11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dataset[[1,2,3,4,5]] == 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that columns 1,2 and 5 have just a few zero values, whereas columns 3 and 4 show a lot more, nearly half of the rows.\n",
    "\n",
    "This highlights that different “missing value” strategies may be needed for different columns, e.g. to ensure that there are still a sufficient number of records left to train a predictive model.\n",
    "\n",
    "In Python, specifically Pandas, NumPy and Scikit-Learn, we mark missing values as NaN.\n",
    "\n",
    "Values with a NaN value are ignored from operations like sum, count, etc.\n",
    "\n",
    "We can mark values as NaN easily with the Pandas DataFrame by using the replace() function on a subset of the columns we are interested in.\n",
    "\n",
    "After we have marked the missing values, we can use the isnull() function to mark all of the NaN values in the dataset as True and get a count of the missing values for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      5\n",
       "2     35\n",
       "3    227\n",
       "4    374\n",
       "5     11\n",
       "6      0\n",
       "7      0\n",
       "8      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mark zero values as missing or NaN\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, np.NaN)\n",
    "# count the number of NaN values in each column\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the columns 1 to 5 have the same number of missing values as zero values identified above. This is a sign that we have marked the identified missing values correctly.\n",
    "\n",
    "This is a useful summary. Let's look at the actual data though, to confirm that 0 has changed to NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>116.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>115.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>197.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>543.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>125.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>110.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0.191</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>168.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.537</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>139.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.1</td>\n",
       "      <td>1.441</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>189.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>846.0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.398</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>166.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>25.8</td>\n",
       "      <td>0.587</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.484</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0.551</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>107.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>103.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.183</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>115.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>34.6</td>\n",
       "      <td>0.529</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0      1     2     3      4     5      6   7  8\n",
       "0    6  148.0  72.0  35.0    NaN  33.6  0.627  50  1\n",
       "1    1   85.0  66.0  29.0    NaN  26.6  0.351  31  0\n",
       "2    8  183.0  64.0   NaN    NaN  23.3  0.672  32  1\n",
       "3    1   89.0  66.0  23.0   94.0  28.1  0.167  21  0\n",
       "4    0  137.0  40.0  35.0  168.0  43.1  2.288  33  1\n",
       "5    5  116.0  74.0   NaN    NaN  25.6  0.201  30  0\n",
       "6    3   78.0  50.0  32.0   88.0  31.0  0.248  26  1\n",
       "7   10  115.0   NaN   NaN    NaN  35.3  0.134  29  0\n",
       "8    2  197.0  70.0  45.0  543.0  30.5  0.158  53  1\n",
       "9    8  125.0  96.0   NaN    NaN   NaN  0.232  54  1\n",
       "10   4  110.0  92.0   NaN    NaN  37.6  0.191  30  0\n",
       "11  10  168.0  74.0   NaN    NaN  38.0  0.537  34  1\n",
       "12  10  139.0  80.0   NaN    NaN  27.1  1.441  57  0\n",
       "13   1  189.0  60.0  23.0  846.0  30.1  0.398  59  1\n",
       "14   5  166.0  72.0  19.0  175.0  25.8  0.587  51  1\n",
       "15   7  100.0   NaN   NaN    NaN  30.0  0.484  32  1\n",
       "16   0  118.0  84.0  47.0  230.0  45.8  0.551  31  1\n",
       "17   7  107.0  74.0   NaN    NaN  29.6  0.254  31  1\n",
       "18   1  103.0  30.0  38.0   83.0  43.3  0.183  33  0\n",
       "19   1  115.0  70.0  30.0   96.0  34.6  0.529  32  1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest strategy for handling missing data is to remove records that contain a missing value.\n",
    "\n",
    "We can do this by creating a new Pandas DataFrame with the rows containing missing values removed.\n",
    "\n",
    "Pandas provides the dropna() function that can be used to drop either columns or rows with missing data. We can use dropna() to remove all rows with missing data, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392, 9)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop rows with missing values\n",
    "dataset.dropna(inplace=True)\n",
    "# summarize the number of rows and columns in the dataset\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the number of rows has been aggressively cut from 768 in the original dataset to 392 with all rows containing a NaN removed.\n",
    "\n",
    "Removing rows with missing values can be too limiting on some predictive modeling problems, an alternative is to impute missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impute Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputing refers to using a model to replace missing values.\n",
    "\n",
    "There are many options we could consider when replacing a missing value, for example:  \n",
    "•A constant value that has meaning within the domain, such as 0, distinct from all other values.  \n",
    "•A value from another randomly selected record.  \n",
    "•A mean, median or mode value for the column.  \n",
    "•A value estimated by another predictive model.\n",
    "\n",
    "Any imputing performed on the training dataset will have to be performed on new data in the future when predictions are needed from the finalized model. This needs to be taken into consideration when choosing how to impute the missing values.\n",
    "\n",
    "For example, if you choose to impute with mean column values, these mean column values will need to be stored to file for later use on new data that has missing values.\n",
    "\n",
    "Pandas provides the fillna() function for replacing missing values with a specific value.\n",
    "\n",
    "For example, we can use fillna() to replace missing values with the mean value for each column, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "5    0\n",
       "6    0\n",
       "7    0\n",
       "8    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "# mark zero values as missing or NaN\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, np.NaN)\n",
    "# fill missing values with mean column values\n",
    "dataset.fillna(dataset.mean(), inplace=True)\n",
    "# count the number of NaN values in each column\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the code provides a count of the number of missing values in each column, showing zero missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scikit-learn library provides the Imputer() pre-processing class that can be used to replace missing values.\n",
    "\n",
    "It is a flexible class that allows you to specify the value to replace (it can be something other than NaN) and the technique used to replace it (such as mean, median, or mode). The Imputer class operates directly on the NumPy array instead of the DataFrame.\n",
    "\n",
    "The code below uses the Imputer class to replace missing values with the mean of each column then prints the number of NaN values in the transformed matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "# mark zero values as missing or NaN\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, np.NaN)\n",
    "# fill missing values with mean column values\n",
    "values = dataset.values\n",
    "imputer = Imputer()\n",
    "transformed_values = imputer.fit_transform(values)\n",
    "# count the number of NaN values in each column\n",
    "np.isnan(transformed_values).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the code shows that all NaN values were imputed successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive Statistics in Python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python Descriptive Statistics process describes the basic features of data in a study. It delivers summaries on the sample and the measures and does not use the data to learn about the population it represents.\n",
    " Under descriptive statistics, fall two sets of properties- central tendency and dispersion. Python Central tendency characterizes one central value for the entire distribution. Measures under this include mean, median, and mode. Python Dispersion is the term for a practice that characterizes how apart the members of the distribution are from the center and from each other. Variance/Standard Deviation is one such measure of variability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Central Tendency in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns the arithmetic average of the data it operates on. If called on an empty container of data, it raises a StatisticsError."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statistics as st\n",
    "nums=[1,2,3,5,7,9] \n",
    "st.mean(nums) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Negative numbers\n",
    "st.mean([-2,-4,7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns the most common value in a set of data. This gives us a great idea of where the center lies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums=[1,2,3,5,7,9,7,2,7,6] \n",
    "st.mode(nums) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.mode(['A','B','b','B','A','B'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For data of odd length, this returns the middle item; for that of even length, it returns the average of the two middle items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.median(nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### harmonic_mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns the harmonic mean of the data. For three values a, b, and c, the harmonic mean is-  \n",
    "3/(1/a + 1/b +1/c)  \n",
    "It is a measure of the center; one such example would be speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.516616314199396"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.harmonic_mean([2,4,9.7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the same set of data, the arithmetic mean would give us a value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.233333333333333"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.mean([2,4,9.7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### median_low()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the data is of an even length, this provides us the low median of the data. Otherwise, it returns the middle value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.median_low([1,2,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.median_low([1,2,3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### median_high()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like median_low, this returns the high median when the data is of an even length. Otherwise, it returns the middle value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.median_high([1,2,4]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.median_high([1,2,3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### median_grouped()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function uses interpolation to return the median of grouped continuous data. This is the 50th percentile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.median([1,3,3,5,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.25"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.median_grouped([1,3,3,5,7],interval=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.median_grouped([1,3,3,5,7],interval=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dispersion in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### variance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns the variance of the sample. This is the second moment about the mean and a larger value denotes a rather spread-out set of data. We can use this when our data is a sample out of a population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.433333333333334"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.variance(nums) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### pvariance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns the population variance of data. Use this to calculate variance from an entire population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.69"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.pvariance(nums) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### stdev()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns the standard deviation for the sample. This is equal to the square root of the sample variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7264140062238043"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.stdev(nums) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### pstdev()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns the population standard deviation. This is the square root of population variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5865034312755126"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.pstdev(nums) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive Statistics on Pima Indians Diabetes Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive statistics is a helpful way to understand characteristics of our data and to get a quick summary of it.\n",
    "\n",
    "The describe() function on the Pandas DataFrame lists 8 statistical properties of each attribute:  \n",
    "•Count  \n",
    "•Mean  \n",
    "•Standard Devaition  \n",
    "•Minimum Value  \n",
    "•25th Percentile  \n",
    "•50th Percentile (Median)  \n",
    "•75th Percentile  \n",
    "•Maximum Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>preg</th>\n",
       "      <td>768.0</td>\n",
       "      <td>3.845</td>\n",
       "      <td>3.370</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plas</th>\n",
       "      <td>768.0</td>\n",
       "      <td>120.895</td>\n",
       "      <td>31.973</td>\n",
       "      <td>0.000</td>\n",
       "      <td>99.000</td>\n",
       "      <td>117.000</td>\n",
       "      <td>140.250</td>\n",
       "      <td>199.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pres</th>\n",
       "      <td>768.0</td>\n",
       "      <td>69.105</td>\n",
       "      <td>19.356</td>\n",
       "      <td>0.000</td>\n",
       "      <td>62.000</td>\n",
       "      <td>72.000</td>\n",
       "      <td>80.000</td>\n",
       "      <td>122.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skin</th>\n",
       "      <td>768.0</td>\n",
       "      <td>20.536</td>\n",
       "      <td>15.952</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>32.000</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>768.0</td>\n",
       "      <td>79.799</td>\n",
       "      <td>115.244</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>30.500</td>\n",
       "      <td>127.250</td>\n",
       "      <td>846.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mass</th>\n",
       "      <td>768.0</td>\n",
       "      <td>31.993</td>\n",
       "      <td>7.884</td>\n",
       "      <td>0.000</td>\n",
       "      <td>27.300</td>\n",
       "      <td>32.000</td>\n",
       "      <td>36.600</td>\n",
       "      <td>67.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pedi</th>\n",
       "      <td>768.0</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.626</td>\n",
       "      <td>2.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>768.0</td>\n",
       "      <td>33.241</td>\n",
       "      <td>11.760</td>\n",
       "      <td>21.000</td>\n",
       "      <td>24.000</td>\n",
       "      <td>29.000</td>\n",
       "      <td>41.000</td>\n",
       "      <td>81.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>768.0</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count     mean      std     min     25%      50%      75%     max\n",
       "preg   768.0    3.845    3.370   0.000   1.000    3.000    6.000   17.00\n",
       "plas   768.0  120.895   31.973   0.000  99.000  117.000  140.250  199.00\n",
       "pres   768.0   69.105   19.356   0.000  62.000   72.000   80.000  122.00\n",
       "skin   768.0   20.536   15.952   0.000   0.000   23.000   32.000   99.00\n",
       "test   768.0   79.799  115.244   0.000   0.000   30.500  127.250  846.00\n",
       "mass   768.0   31.993    7.884   0.000  27.300   32.000   36.600   67.10\n",
       "pedi   768.0    0.472    0.331   0.078   0.244    0.372    0.626    2.42\n",
       "age    768.0   33.241   11.760  21.000  24.000   29.000   41.000   81.00\n",
       "class  768.0    0.349    0.477   0.000   0.000    0.000    1.000    1.00"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "data = read_csv('pima-indians-diabetes.csv', names=names)\n",
    "pd.set_option('display.width', 100)\n",
    "pd.set_option('precision', 3)\n",
    "description = data.describe().T\n",
    "description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we replace 0 with NaN in columns where 0 is missing value and see how the result changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_csv('pima-indians-diabetes.csv', names = names)\n",
    "# mark zero values as missing or NaN\n",
    "data[['plas', 'pres', 'skin', 'test', 'mass']] = data[['plas', 'pres', 'skin', 'test', 'mass']].replace(0, np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>preg</th>\n",
       "      <td>768.0</td>\n",
       "      <td>3.845</td>\n",
       "      <td>3.370</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plas</th>\n",
       "      <td>763.0</td>\n",
       "      <td>121.687</td>\n",
       "      <td>30.536</td>\n",
       "      <td>44.000</td>\n",
       "      <td>99.000</td>\n",
       "      <td>117.000</td>\n",
       "      <td>141.000</td>\n",
       "      <td>199.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pres</th>\n",
       "      <td>733.0</td>\n",
       "      <td>72.405</td>\n",
       "      <td>12.382</td>\n",
       "      <td>24.000</td>\n",
       "      <td>64.000</td>\n",
       "      <td>72.000</td>\n",
       "      <td>80.000</td>\n",
       "      <td>122.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skin</th>\n",
       "      <td>541.0</td>\n",
       "      <td>29.153</td>\n",
       "      <td>10.477</td>\n",
       "      <td>7.000</td>\n",
       "      <td>22.000</td>\n",
       "      <td>29.000</td>\n",
       "      <td>36.000</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>394.0</td>\n",
       "      <td>155.548</td>\n",
       "      <td>118.776</td>\n",
       "      <td>14.000</td>\n",
       "      <td>76.250</td>\n",
       "      <td>125.000</td>\n",
       "      <td>190.000</td>\n",
       "      <td>846.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mass</th>\n",
       "      <td>757.0</td>\n",
       "      <td>32.457</td>\n",
       "      <td>6.925</td>\n",
       "      <td>18.200</td>\n",
       "      <td>27.500</td>\n",
       "      <td>32.300</td>\n",
       "      <td>36.600</td>\n",
       "      <td>67.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pedi</th>\n",
       "      <td>768.0</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.626</td>\n",
       "      <td>2.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>768.0</td>\n",
       "      <td>33.241</td>\n",
       "      <td>11.760</td>\n",
       "      <td>21.000</td>\n",
       "      <td>24.000</td>\n",
       "      <td>29.000</td>\n",
       "      <td>41.000</td>\n",
       "      <td>81.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>768.0</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count     mean      std     min     25%      50%      75%     max\n",
       "preg   768.0    3.845    3.370   0.000   1.000    3.000    6.000   17.00\n",
       "plas   763.0  121.687   30.536  44.000  99.000  117.000  141.000  199.00\n",
       "pres   733.0   72.405   12.382  24.000  64.000   72.000   80.000  122.00\n",
       "skin   541.0   29.153   10.477   7.000  22.000   29.000   36.000   99.00\n",
       "test   394.0  155.548  118.776  14.000  76.250  125.000  190.000  846.00\n",
       "mass   757.0   32.457    6.925  18.200  27.500   32.300   36.600   67.10\n",
       "pedi   768.0    0.472    0.331   0.078   0.244    0.372    0.626    2.42\n",
       "age    768.0   33.241   11.760  21.000  24.000   29.000   41.000   81.00\n",
       "class  768.0    0.349    0.477   0.000   0.000    0.000    1.000    1.00"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see count has decreased in columns having missing values and also other metrics have also changes as any missing value or NaN value is automatically skipped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful method is value_counts() which can get count of each category in a categorical attributed series of values. For an instance suppose we are dealing with a dataset of customers who are divided as 0 and 1 categories under column name class. We can run this statement to know how many people fall in respective categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"class\"].value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more useful tool is boxplot which we can use through matplotlib module. Boxplot is a pictorial representation of distribution of data which shows extreme values, median and quartiles. We can easily figure out outliers by using boxplots. Now consider the dataset we’ve been dealing with again and lets draw a boxplot on attribute preg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "y = list(data.preg) \n",
    "plt.boxplot(y) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output plot would look like this with spotting out outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is ANOVA (ANalysis Of VAriance)?\n",
    "\n",
    "•Used to compare the means of more than 2 groups (t-test can be used to compare 2 groups)  \n",
    "•Groups mean differences inferred by analyzing variances  \n",
    "•Main types: One-way (one factor) and two-way (two factors) ANOVA (factor is an independent variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANOVA Hypotheses\n",
    "\n",
    "•Null hypotheses: Groups means are equal (no variation in means of groups)  \n",
    "•Alternative hypotheses: At least, one group mean is different from other groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANOVA Assumptions\n",
    "\n",
    "•Residuals (experimental error) are normally distributed  \n",
    "•Homogeneity of variances (variances are equal between treatment groups)  \n",
    "•Observations are sampled independently from each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How ANOVA works?\n",
    "\n",
    "•Check sample sizes: equal number of observation in each group(SS)  \n",
    "•Calculate Mean Square for each group (MS) (SS of group/level-1);  \n",
    "level-1 is a degree of freedom (df) for a group  \n",
    "•Calculate Mean Square error (MSE) (SS error/df of residuals)  \n",
    "•Calculate F-value (MS of group/MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-way (one factor) ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# load data file\n",
    "d = pd.read_csv('Anova.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>45</td>\n",
       "      <td>30</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>55</td>\n",
       "      <td>29</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>33</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>56</td>\n",
       "      <td>37</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>40</td>\n",
       "      <td>27</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A   B   C   D\n",
       "0  25  45  30  54\n",
       "1  30  55  29  60\n",
       "2  28  29  33  51\n",
       "3  36  56  37  62\n",
       "4  29  40  27  73"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, there are four treatments (A, B, C, and D), which are groups for ANOVA analysis. Treatments are independent variable and termed as factor. As there are four types of treatments, treatment factor has four levels.\n",
    "\n",
    "For this experimental design, there is only factor (treatments) or independent variable to evaluate, and therefore, one-way ANOVA is suitable for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x26de189ab70>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate a boxplot to see the data distribution by treatments. \n",
    "#Using boxplot, we can easily detect the differences between different treatments\n",
    "d.boxplot(column=['A', 'B', 'C', 'D'], grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.492810457516338 2.639241146210922e-05\n"
     ]
    }
   ],
   "source": [
    "# load packages\n",
    "import scipy.stats as stats\n",
    "# stats f_oneway functions takes the groups as input and returns F and P-value\n",
    "fvalue, pvalue = stats.f_oneway(d['A'], d['B'], d['C'], d['D'])\n",
    "print(fvalue, pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation: The P-value obtained from ANOVA analysis is significant (P<0.05), and therefore, we conclude that there are significant differences among treatments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questionnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Why do we need missing value imputation over rows deletion?\n",
    "\n",
    "The two major advantages of missing data imputation over rows deletion:  \n",
    "1.The variance of analyses based on imputed data is usually lower, since missing data imputation does not reduce your sample size.  \n",
    "2.Depending on the response mechanism, missing data imputation outperforms rows deletion in terms of bias.   \n",
    "Missing data imputation almost always improves the quality of our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What are theproblems with using mean-imputed variables in statistical analyses?\n",
    "\n",
    "There are three problems with using mean-imputed variables in statistical analyses:   \n",
    "1.Mean imputation reduces the variance of the imputed variables.  \n",
    "2.Mean imputation shrinks standard errors, which invalidates most hypothesis tests and the calculation of confidence interval.  \n",
    "3.Mean imputation does not preserve relationships between variables such as correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Which value can be used for missing value imputation?\n",
    "\n",
    "Often a simple, if not always satisfactory, choice for missing values that are known not to be zero is to use some 'central' value of the variable. This is often the mean, median, or mode, and thus usually has limited impact on the distribution. We might choose to use the mean, for example, if the variable is otherwise generally normally distributed (and in particular does not have any skewness). If the data does exhibit some skewness though (e.g., there are a small number of very large values) then the median might be a better choice. \n",
    "\n",
    "For categoric variables, there is, of course, no mean nor median, and so in such cases we might choose to use the mode (the most frequent value) as the default to fill in for the otherwise missing values. The mode can also be used for numeric variables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
